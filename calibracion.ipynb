{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibración de la cámara completada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Definir el número de esquinas internas del tablero de ajedrez\n",
    "chessboard_size = (8, 5)\n",
    "\n",
    "# Preparar puntos de objeto como (0,0,0), (1,0,0), (2,0,0), ....,(8,5,0)\n",
    "objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays para almacenar los puntos del objeto 3D y los puntos de la imagen 2D de todas las imágenes\n",
    "objpoints = []  # puntos 3D en el mundo real\n",
    "imgpoints = []  # puntos 2D en el plano de la imagen\n",
    "\n",
    "# Cargar todas las imágenes de calibración\n",
    "images = glob.glob('imagenes/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Encontrar las esquinas del tablero de ajedrez\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "\n",
    "    # Si se encuentran, añadir puntos de objeto y puntos de imagen\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Dibujar y mostrar las esquinas del tablero de ajedrez\n",
    "        cv2.drawChessboardCorners(img, chessboard_size, corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calibrar la cámara\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Guardar los parámetros de calibración\n",
    "np.savez('calibracion_camara.npz', ret=ret, mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n",
    "\n",
    "print(\"Calibración de la cámara completada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la calibración\n",
    "calibration_data = np.load('calibracion_camara.npz')\n",
    "mtx = calibration_data['mtx']\n",
    "dist = calibration_data['dist']\n",
    "\n",
    "# Cargar una imagen para de-distorsionar\n",
    "img = cv2.imread('aruco2.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Obtener la nueva matriz de cámara y la región de interés\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "# De-distorsionar la imagen\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# Recortar la imagen utilizando la región de interés\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('Imagen De-distorsionada2', dst)\n",
    "cv2.imwrite('imagen_dedistorsionada2.jpg', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import random\n",
    "\n",
    "def create_aruco_marker(dict_type, marker_id, size):\n",
    "    aruco_dict = aruco.getPredefinedDictionary(dict_type)\n",
    "    img_marker = np.zeros((size, size), dtype=np.uint8)\n",
    "    img_marker = aruco.drawMarker(aruco_dict, marker_id, size)\n",
    "    return img_marker\n",
    "\n",
    "# Parámetros para el marcador\n",
    "dict_type = aruco.DICT_6X6_250\n",
    "size = 700\n",
    "\n",
    "# Generar un marker_id aleatorio entre 0 y el número máximo de IDs permitidos por el diccionario\n",
    "max_ids = aruco.getPredefinedDictionary(dict_type).bytesList.shape[0] - 1\n",
    "marker_id = random.randint(0, max_ids)\n",
    "\n",
    "# Crear y guardar el marcador ARUCO\n",
    "img_marker = create_aruco_marker(dict_type, marker_id, size)\n",
    "cv2.imwrite(f'marcador_aruco_{marker_id}.png', img_marker)\n",
    "\n",
    "# Mostrar el marcador\n",
    "cv2.imshow(f'Marcador ARUCO ID {marker_id}', img_marker)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "¡Alarma! Objeto detectado en el área del rectángulo.\n",
      "No se pudo leer el fotograma.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# Ajustar el tamaño del marcador en metros\n",
    "tamaño_marcador = 0.17  # Tamaño del marcador ARUCO en metros\n",
    "\n",
    "def reproducir_alarma():\n",
    "    frecuencia = 1000  # Frecuencia en Hertz\n",
    "    duracion = 1000    # Duración en milisegundos\n",
    "    winsound.Beep(frecuencia, duracion)\n",
    "\n",
    "def detectar_marcador_aruco_y_objetos(calibration_data_path, ip_camera_url):\n",
    "    # Cargar los parámetros de la cámara desde la calibración previa\n",
    "    calibration_data = np.load(calibration_data_path)\n",
    "    mtx = calibration_data['mtx']\n",
    "    dist = calibration_data['dist']\n",
    "\n",
    "    # Inicializar la captura de video desde la cámara IP\n",
    "    cap = cv2.VideoCapture(ip_camera_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    # Cargar el modelo de detección de objetos desde TensorFlow Hub\n",
    "    detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "    alarma_activada = False\n",
    "    tiempo_alarma = 0\n",
    "    intervalo_alarma = 5  # Intervalo de tiempo en segundos entre alarmas\n",
    "\n",
    "    while True:\n",
    "        # Capturar un fotograma de video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se pudo leer el fotograma.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar los marcadores ARUCO\n",
    "        aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "        if ids is not None and len(ids) == 4:\n",
    "            # Dibujar los bordes de los marcadores detectados\n",
    "            frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Ordenar los marcadores por ID para mantener un orden consistente\n",
    "            ids = ids.flatten()\n",
    "            orden = np.argsort(ids)\n",
    "            corners = [corners[i] for i in orden]\n",
    "\n",
    "            # Obtener las posiciones de las esquinas de los marcadores\n",
    "            puntos_rectangulo = np.array([corner[0][0] for corner in corners], dtype=np.int32)\n",
    "\n",
    "            # Dibujar el rectángulo prohibido en la imagen\n",
    "            cv2.polylines(frame, [puntos_rectangulo], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # Detección de personas y objetos\n",
    "            input_tensor = tf.convert_to_tensor(frame)\n",
    "            input_tensor = input_tensor[tf.newaxis, ...]\n",
    "            detections = detector(input_tensor)\n",
    "\n",
    "            # Procesar las detecciones y verificar si están dentro de la región prohibida\n",
    "            objeto_detectado = False\n",
    "            for i in range(int(detections['num_detections'])):\n",
    "                class_id = int(detections['detection_classes'][0][i])\n",
    "                score = detections['detection_scores'][0][i]\n",
    "                bbox = detections['detection_boxes'][0][i]\n",
    "                if score > 0.5:  # Filtrar detecciones con confianza mayor a 50%\n",
    "                    # Convertir de coordenadas relativas a píxeles\n",
    "                    ymin, xmin, ymax, xmax = bbox\n",
    "                    (startX, startY, endX, endY) = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]),\n",
    "                                                    int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
    "\n",
    "                    # Dibujar la caja de detección en la imagen\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "                    # Verificar si el objeto está dentro de la región prohibida\n",
    "                    centro_objeto = ((startX + endX) // 2, (startY + endY) // 2)\n",
    "                    if cv2.pointPolygonTest(puntos_rectangulo, centro_objeto, False) >= 0:\n",
    "                        objeto_detectado = True\n",
    "                        break\n",
    "\n",
    "            # Manejar la alarma\n",
    "            if objeto_detectado:\n",
    "                if not alarma_activada or (time.time() - tiempo_alarma > intervalo_alarma):\n",
    "                    reproducir_alarma()\n",
    "                    alarma_activada = True\n",
    "                    tiempo_alarma = time.time()\n",
    "                print(\"¡Alarma! Objeto detectado en el área del rectángulo.\")\n",
    "            else:\n",
    "                alarma_activada = False  # Resetear el estado de la alarma si no hay objeto detectado\n",
    "\n",
    "        # Mostrar la imagen con el rectángulo prohibido proyectado y detecciones\n",
    "        cv2.imshow('Detección de Objetos y Región Prohibida', frame)\n",
    "\n",
    "        # Salir si se presiona la tecla 'q' o se cierra la ventana\n",
    "        if cv2.getWindowProperty('Detección de Objetos y Región Prohibida', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar la captura y cerrar todas las ventanas\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Reemplaza 'http://192.168.1.100:8080/video' con la dirección IP de tu teléfono.\n",
    "ip_camera_url = 'http://192.168.100.130:4747/video'\n",
    "detectar_marcador_aruco_y_objetos('calibracion_camara.npz', ip_camera_url) \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# Ajustar el tamaño del marcador en metros\n",
    "tamaño_marcador = 0.17  # Tamaño del marcador ARUCO en metros\n",
    "\n",
    "def reproducir_alarma():\n",
    "    frecuencia = 1000  # Frecuencia en Hertz\n",
    "    duracion = 1000    # Duración en milisegundos\n",
    "    winsound.Beep(frecuencia, duracion)\n",
    "\n",
    "def detectar_marcador_aruco_y_objetos(calibration_data_path, ip_camera_url):\n",
    "    # Cargar los parámetros de la cámara desde la calibración previa\n",
    "    calibration_data = np.load(calibration_data_path)\n",
    "    mtx = calibration_data['mtx']\n",
    "    dist = calibration_data['dist']\n",
    "\n",
    "    # Inicializar la captura de video desde la cámara IP\n",
    "    cap = cv2.VideoCapture(ip_camera_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    # Cargar el modelo de detección de objetos desde TensorFlow Hub\n",
    "    detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "    alarma_activada = False\n",
    "    tiempo_alarma = 0\n",
    "    intervalo_alarma = 5  # Intervalo de tiempo en segundos entre alarmas\n",
    "\n",
    "    while True:\n",
    "        # Capturar un fotograma de video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se pudo leer el fotograma.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar los marcadores ARUCO\n",
    "        aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "        if ids is not None and len(ids) == 4:\n",
    "            # Dibujar los bordes de los marcadores detectados\n",
    "            frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Ordenar los marcadores por ID para mantener un orden consistente\n",
    "            ids = ids.flatten()\n",
    "            orden = np.argsort(ids)\n",
    "            corners = [corners[i] for i in orden]\n",
    "\n",
    "            # Obtener las posiciones de las esquinas de los marcadores\n",
    "            puntos_rectangulo = np.array([corner[0][0] for corner in corners], dtype=np.int32)\n",
    "\n",
    "            # Dibujar el rectángulo prohibido en la imagen\n",
    "            cv2.polylines(frame, [puntos_rectangulo], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # Detección de personas y objetos\n",
    "            input_tensor = tf.convert_to_tensor(frame)\n",
    "            input_tensor = input_tensor[tf.newaxis, ...]\n",
    "            detections = detector(input_tensor)\n",
    "\n",
    "            # Procesar las detecciones y verificar si están dentro de la región prohibida\n",
    "            objeto_detectado = False\n",
    "            persona_detectada = False\n",
    "            for i in range(int(detections['num_detections'])):\n",
    "                class_id = int(detections['detection_classes'][0][i])\n",
    "                score = detections['detection_scores'][0][i]\n",
    "                bbox = detections['detection_boxes'][0][i]\n",
    "                if score > 0.5:  # Filtrar detecciones con confianza mayor a 50%\n",
    "                    # Convertir de coordenadas relativas a píxeles\n",
    "                    ymin, xmin, ymax, xmax = bbox\n",
    "                    (startX, startY, endX, endY) = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]),\n",
    "                                                    int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
    "\n",
    "                    # Dibujar la caja de detección en la imagen\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "                    # Verificar si el objeto está dentro de la región prohibida\n",
    "                    centro_objeto = ((startX + endX) // 2, (startY + endY) // 2)\n",
    "                    if cv2.pointPolygonTest(puntos_rectangulo, centro_objeto, False) >= 0:\n",
    "                        objeto_detectado = True\n",
    "                        if class_id == 1:  # class_id 1 corresponde a 'person'\n",
    "                            persona_detectada = True\n",
    "                        break\n",
    "\n",
    "            # Mostrar mensajes en la imagen\n",
    "            if persona_detectada:\n",
    "                cv2.putText(frame, \"Persona detectada en la zona prohibida!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                if not alarma_activada or (time.time() - tiempo_alarma > intervalo_alarma):\n",
    "                    reproducir_alarma()\n",
    "                    alarma_activada = True\n",
    "                    tiempo_alarma = time.time()\n",
    "            elif objeto_detectado:\n",
    "                cv2.putText(frame, \"Objeto detectado, pero no es una persona\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                alarma_activada = False  # Resetear el estado de la alarma si no hay objeto detectado\n",
    "\n",
    "        # Mostrar la imagen con el rectángulo prohibido proyectado y detecciones\n",
    "        cv2.imshow('Detección de Objetos y Región Prohibida', frame)\n",
    "\n",
    "        # Salir si se presiona la tecla 'q' o se cierra la ventana\n",
    "        if cv2.getWindowProperty('Detección de Objetos y Región Prohibida', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar la captura y cerrar todas las ventanasq\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Reemplaza 'http://192.168.1.100:8080/video' con la dirección IP de tu teléfono.\n",
    "ip_camera_url = 'http://192.168.100.130:4747/video'\n",
    "detectar_marcador_aruco_y_objetos('calibracion_camara.npz', ip_camera_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# Ajustar el tamaño del marcador en metros\n",
    "tamaño_marcador = 0.17  # Tamaño del marcador ARUCO en metros\n",
    "\n",
    "def reproducir_alarma():\n",
    "    frecuencia = 1000  # Frecuencia en Hertz\n",
    "    duracion = 1000    # Duración en milisegundos\n",
    "    winsound.Beep(frecuencia, duracion)\n",
    "\n",
    "def detectar_marcador_aruco_y_objetos(calibration_data_path, ip_camera_url):\n",
    "    # Cargar los parámetros de la cámara desde la calibración previa\n",
    "    calibration_data = np.load(calibration_data_path)\n",
    "    mtx = calibration_data['mtx']\n",
    "    dist = calibration_data['dist']\n",
    "\n",
    "    # Inicializar la captura de video desde la cámara IP\n",
    "    cap = cv2.VideoCapture(ip_camera_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    # Cargar el modelo de detección de objetos desde TensorFlow Hub\n",
    "    detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "    alarma_activada = False\n",
    "    tiempo_alarma = 0\n",
    "    intervalo_alarma = 5  # Intervalo de tiempo en segundos entre alarmas\n",
    "\n",
    "    while True:\n",
    "        # Capturar un fotograma de video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se pudo leer el fotograma.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar los marcadores ARUCO\n",
    "        aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "        if ids is not None and len(ids) == 4:\n",
    "            # Dibujar los bordes de los marcadores detectados\n",
    "            frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Ordenar los marcadores por ID para mantener un orden consistente\n",
    "            ids = ids.flatten()\n",
    "            orden = np.argsort(ids)\n",
    "            corners = [corners[i] for i in orden]\n",
    "\n",
    "            # Obtener las posiciones de las esquinas de los marcadores\n",
    "            puntos_rectangulo = np.array([corner[0][0] for corner in corners], dtype=np.int32)\n",
    "\n",
    "            # Dibujar el rectángulo prohibido en la imagen\n",
    "            cv2.polylines(frame, [puntos_rectangulo], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # Detección de personas y objetos\n",
    "            input_tensor = tf.convert_to_tensor(frame)\n",
    "            input_tensor = input_tensor[tf.newaxis, ...]\n",
    "            detections = detector(input_tensor)\n",
    "\n",
    "            # Procesar las detecciones y verificar si están dentro de la región prohibida\n",
    "            objeto_detectado = False\n",
    "            persona_detectada = False\n",
    "            for i in range(int(detections['num_detections'])):\n",
    "                class_id = int(detections['detection_classes'][0][i])\n",
    "                score = detections['detection_scores'][0][i]\n",
    "                bbox = detections['detection_boxes'][0][i]\n",
    "                if score > 0.5:  # Filtrar detecciones con confianza mayor a 50%\n",
    "                    # Convertir de coordenadas relativas a píxeles\n",
    "                    ymin, xmin, ymax, xmax = bbox\n",
    "                    (startX, startY, endX, endY) = (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]),\n",
    "                                                    int(xmax * frame.shape[1]), int(ymax * frame.shape[0]))\n",
    "\n",
    "                    # Dibujar la caja de detección en la imagen\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "                    # Verificar si el objeto está dentro de la región prohibida\n",
    "                    centro_objeto = ((startX + endX) // 2, (startY + endY) // 2)\n",
    "                    if cv2.pointPolygonTest(puntos_rectangulo, centro_objeto, False) >= 0:\n",
    "                        objeto_detectado = True\n",
    "                        if class_id == 1:  # class_id 1 corresponde a 'person'\n",
    "                            persona_detectada = True\n",
    "                        break\n",
    "\n",
    "            # Mostrar mensajes en la imagen\n",
    "            if persona_detectada:\n",
    "                cv2.putText(frame, \"Persona detectada en la zona prohibida!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                if not alarma_activada or (time.time() - tiempo_alarma > intervalo_alarma):\n",
    "                    reproducir_alarma()\n",
    "                    alarma_activada = True\n",
    "                    tiempo_alarma = time.time()\n",
    "            elif objeto_detectado:\n",
    "                cv2.putText(frame, \"Objeto detectado, pero no es una persona\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (255, 255, 0), 2, cv2.LINE_AA)\n",
    "                if not alarma_activada or (time.time() - tiempo_alarma > intervalo_alarma):\n",
    "                    reproducir_alarma()\n",
    "                    alarma_activada = True\n",
    "                    tiempo_alarma = time.time()\n",
    "            else:\n",
    "                alarma_activada = False  # Resetear el estado de la alarma si no hay objeto detectado\n",
    "\n",
    "        # Mostrar la imagen con el rectángulo prohibido proyectado y detecciones\n",
    "        cv2.imshow('Detección de Objetos y Región Prohibida', frame)\n",
    "\n",
    "        # Salir si se presiona la tecla 'q' o se cierra la ventana\n",
    "        if cv2.getWindowProperty('Detección de Objetos y Región Prohibida', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar la captura y cerrar todas las ventanasq\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Reemplaza 'http://192.168.1.100:8080/video' con la dirección IP de tu teléfono.\n",
    "ip_camera_url = 'http://192.168.100.130:4747/video'\n",
    "detectar_marcador_aruco_y_objetos('calibracion_camara.npz', ip_camera_url)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
